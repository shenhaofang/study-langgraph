{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83fcadf3",
   "metadata": {},
   "source": [
    "[![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239436-lesson-5-chatbot-w-summarizing-messages-and-memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651ead9-5504-45ee-938d-f91ac78dddd1",
   "metadata": {},
   "source": [
    "# 具有消息摘要功能的聊天机器人\n",
    "\n",
    "## 回顾\n",
    "\n",
    "我们已经介绍了怎样自定义图状态模式和汇总器 reducer。 \n",
    " \n",
    "我们还展示了多种裁剪或过滤图状态中消息的方法。\n",
    "\n",
    "## 目标\n",
    "\n",
    "现在，让我们更进一步\n",
    "\n",
    "不仅仅是裁剪和过滤消息，我们将展示怎样使用LLMs来生成对话的实时摘要。\n",
    " \n",
    "这允许我们保留整个对话的一个压缩表示，而不是仅仅是通过裁剪或过滤删除它。\n",
    "\n",
    "我们将把这个摘要集成到一个简单的聊天机器人中。\n",
    "\n",
    "我们还将为这个聊天机器人装备记忆功能，支持长时间对话而不会产生高额token消耗/延迟。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a6daa-92ad-4e57-a060-d1c81176eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_core langgraph langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09201a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2749cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我没有openai的api key，所以使用qwen的openai兼容接口，需要设置qwen的api key和base url，我选择从配置文件.yml中读取\n",
    "import yaml\n",
    "\n",
    "with open(\"../.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "qwen_config = config[\"llm\"][\"qwen\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddfce9-3a9b-4b35-a76d-28265515aabd",
   "metadata": {},
   "source": [
    "我们将使用 [LangSmith](https://docs.smith.langchain.com/) 进行 [追踪](https://docs.smith.langchain.com/concepts/tracing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "464856d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# _set_env(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = config[\"langsmith\"][\"key\"]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-study\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "537ade30-6a0e-4b6b-8bcd-ce90790b6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"qwen-max\",api_key=qwen_config[\"api_key\"],base_url=qwen_config[\"base_url\"],temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3afac3-8b7a-45db-a3c1-7e4125c1bc8b",
   "metadata": {},
   "source": [
    "像之前一样，我们将使用 `MessagesState`。\n",
    "\n",
    "除了内置的 `messages` 键，我们现在将引入一个自定义的键（`summary`）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "948e60f0-5c76-4235-b40e-cf523205d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "class State(MessagesState):\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855ea31-5cc1-4277-a189-0b72459f67ec",
   "metadata": {},
   "source": [
    "我们将定义一个调用我们LLM的节点，如果存在摘要，将其纳入提示词中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f7d19b-afe0-4381-9b1a-0a832b162e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882042c-b42d-4d52-a6a7-6ec8efa72450",
   "metadata": {},
   "source": [
    "我们将定义一个节点来生成摘要。\n",
    "\n",
    "注意，这里我们将在生成摘要后使用 `RemoveMessage` 来过滤我们的状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78c7aa59-3760-4e76-93f1-bc713e3ec39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above, only output the summary, no other text:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above, only output the summary, no other text:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f982993e-f4be-4ff7-9a38-886f75398b3d",
   "metadata": {},
   "source": [
    "我们将添加一个条件边来根据对话长度决定是否生成摘要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b507665d-7f5d-442a-b498-218c94c5dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a838f4c-7067-4f7f-a4c4-6654e11214cd",
   "metadata": {},
   "source": [
    "## 添加记忆\n",
    "\n",
    "回忆知识点：对一次单个图执行来说[状态是瞬时的](https://github.com/langchain-ai/langgraph/discussions/352#discussioncomment-9291220) 。\n",
    "\n",
    "这限制了我们拥有可中断的多轮对话的能力。\n",
    "\n",
    "正如 Module 1 结尾所介绍的，我们可以使用[持久化](https://langchain-ai.github.io/langgraph/how-tos/persistence/)来解决这个问题。\n",
    " \n",
    "LangGraph 可以使用一个检查器在每一步后自动保存图状态。\n",
    "\n",
    "这个内置的持久化层给我们提供了记忆，允许 LangGraph 从最后一次状态更新处恢复。\n",
    "\n",
    "正如我们之前所展示的，最容易使用的一个是 `MemorySaver`，一个图状态的内存键值对存储。\n",
    "\n",
    "我们所需要做的就是用一个检查器来编译图，我们的图就有了记忆！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d57516d-f9f1-4d3c-a84a-7277b5ce6df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tconversation(conversation)\n",
      "\tsummarize_conversation(summarize_conversation)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> conversation;\n",
      "\tsummarize_conversation --> __end__;\n",
      "\tconversation -.-> summarize_conversation;\n",
      "\tconversation -.-> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "print(graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0bd5d23-ac3b-4496-a049-9a9f97d2feb9",
   "metadata": {},
   "source": [
    "## Threads\n",
    "\n",
    "检查器在每一步后保存状态作为检查点。\n",
    "\n",
    "这些保存的检查点可以被分组到一个对话的 `thread` 中。\n",
    "\n",
    "将Slack（一款团队协作沟通工具类似飞书吧）当做类比：不同的频道承载了不同的对话。\n",
    "\n",
    "![slack.png](./slack.png)\n",
    "\n",
    "Threads 就像 Slack 的频道, 捕捉分组的状态集合（例如，对话）。\n",
    "\n",
    "下边，我们使用 `configurable` 来设置 thread ID.\n",
    "\n",
    "![state.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbadf3b379c2ee621adfd1_chatbot-summarization1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2566c93b-13e6-4a53-bc0f-b00fff691d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Lance! It's great to meet you. How can I assist you today? Whether you have questions, need information, or just want to chat about something, feel free to let me know!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Lance! Is there anything else you'd like to know or discuss?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great, Lance! The San Francisco 49ers have a rich history and a passionate fan base. Do you have a favorite player, or are you looking forward to any upcoming games? Or maybe you'd like to talk about some memorable moments in 49ers history?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "memory.storage.clear()\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"what's my name?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"i like the 49ers!\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e5b63-5e8b-486e-baa0-a45521e2fbc2",
   "metadata": {},
   "source": [
    "现在，我们还没有状态的摘要，因为我们的消息仍然<=6条。\n",
    "\n",
    "这是在 `should_continue` 中设置的。\n",
    "\n",
    "```\n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "```\n",
    "\n",
    "我们可以恢复对话因为我们拥有 thread。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91b82aaa-17f9-49e2-9528-f4b22e23ebcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"summary\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a93e9-f716-4980-8edf-94115017d865",
   "metadata": {},
   "source": [
    "这个带有 thread ID 的 `config` 允许我们从之前记录的状态继续进行！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24b34f0f-62ef-4008-8e96-480cbe92ea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yes, you're right! Nick Bosa is one of the top defensive players in the NFL, and he recently signed a massive contract extension with the San Francisco 49ers. In March 2023, he signed a five-year, $130 million deal, making him the highest-paid defensive player in the league at that time. His performance on the field has been outstanding, and he's a key part of the 49ers' defense.\n",
      "\n",
      "Do you have any favorite moments or plays from Nick Bosa, or are you excited about how he'll perform this season?\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"i like Nick Bosa, isn't he the highest paid defensive player?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22f1b35f-e4bb-47f6-87b1-d84d8aed9aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lance introduced himself and mentioned he likes the San Francisco 49ers. He specifically noted his appreciation for Nick Bosa, who recently signed a five-year, $130 million contract, making him the highest-paid defensive player in the NFL.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"summary\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7cc0ab-905a-4037-b7cb-69db5b89591e",
   "metadata": {},
   "source": [
    "## LangSmith\n",
    "\n",
    "让我们检查一下追踪信息。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchan-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
